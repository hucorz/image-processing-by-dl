{"env_info": "sys.platform: linux\nPython: 3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\nCUDA available: True\nGPU 0: Tesla K80\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 11.1, V11.1.105\nGCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.11.0+cu113\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.3\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.2\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.12.0+cu113\nOpenCV: 4.1.2\nMMCV: 1.5.0\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.3\nMMClassification: 0.23.0+7c5ddb1", "seed": 998345085, "mmcls_version": "0.23.0", "config": "model = dict(\n    type='ImageClassifier',\n    backbone=dict(\n        type='VisionTransformer',\n        arch='b',\n        img_size=224,\n        patch_size=16,\n        drop_rate=0.1,\n        init_cfg=[\n            dict(\n                type='Pretrained',\n                checkpoint=\n                'checkpoint/vit-base-p16_in21k-pre-3rdparty_ft-64xb64_in1k-384_20210928-98e8652b.pth',\n                prefix='backbone')\n        ]),\n    neck=None,\n    head=dict(\n        type='VisionTransformerClsHead',\n        num_classes=5,\n        in_channels=768,\n        loss=dict(\n            type='LabelSmoothLoss', label_smooth_val=0.1,\n            mode='classy_vision'),\n        topk=(1, )))\noptimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='step', step=3, gamma=0.1)\nrunner = dict(type='EpochBasedRunner', max_epochs=5)\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'checkpoint/vit-base-p16_in21k-pre-3rdparty_ft-64xb64_in1k-384_20210928-98e8652b.pth'\nresume_from = None\nworkflow = [('train', 1)]\ncheckpoint_path = 'checkpoint/vit-base-p16_in21k-pre-3rdparty_ft-64xb64_in1k-384_20210928-98e8652b.pth'\ndataset_type = 'ImageNet'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='RandomResizedCrop', size=224),\n    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='ImageToTensor', keys=['img']),\n    dict(type='ToTensor', keys=['gt_label']),\n    dict(type='Collect', keys=['img', 'gt_label'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='Resize', size=(256, -1)),\n    dict(type='CenterCrop', crop_size=224),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='ImageToTensor', keys=['img']),\n    dict(type='Collect', keys=['img'])\n]\ndata = dict(\n    samples_per_gpu=32,\n    workers_per_gpu=4,\n    train=dict(\n        type='ImageNet',\n        data_prefix='data/flower_data/train',\n        ann_file='data/flower_data/train_annotations.txt',\n        classes='data/flower_data/classes.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='RandomResizedCrop', size=224),\n            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='ToTensor', keys=['gt_label']),\n            dict(type='Collect', keys=['img', 'gt_label'])\n        ]),\n    val=dict(\n        type='ImageNet',\n        data_prefix='data/flower_data/val',\n        ann_file='data/flower_data/val_annotations.txt',\n        classes='data/flower_data/classes.txt',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='Resize', size=(256, -1)),\n            dict(type='CenterCrop', crop_size=224),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ]))\nevaluation = dict(metric='accuracy', metric_options=dict(topk=(1, )))\nwork_dir = './work_dirs/vit-base-p16_1xb32_flower'\ngpu_ids = [0]\nseed = 998345085\n", "CLASSES": ["daisy", "dandelion", "roses", "sunflowers", "tulips"]}
{"mode": "train", "epoch": 1, "iter": 10, "lr": 0.005, "memory": 5690, "data_time": 0.28421, "loss": 1.42333, "time": 2.66469}
{"mode": "train", "epoch": 1, "iter": 20, "lr": 0.005, "memory": 5690, "data_time": 0.10162, "loss": 1.47095, "time": 2.47501}
{"mode": "train", "epoch": 1, "iter": 30, "lr": 0.005, "memory": 5690, "data_time": 0.10256, "loss": 1.50456, "time": 2.48028}
{"mode": "train", "epoch": 1, "iter": 40, "lr": 0.005, "memory": 5690, "data_time": 0.10196, "loss": 1.18683, "time": 2.48072}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.005, "memory": 5690, "data_time": 0.10204, "loss": 1.10252, "time": 2.48258}
{"mode": "train", "epoch": 1, "iter": 60, "lr": 0.005, "memory": 5690, "data_time": 0.10197, "loss": 1.02523, "time": 2.48191}
{"mode": "train", "epoch": 1, "iter": 70, "lr": 0.005, "memory": 5690, "data_time": 0.10217, "loss": 1.08966, "time": 2.48198}
{"mode": "train", "epoch": 1, "iter": 80, "lr": 0.005, "memory": 5690, "data_time": 0.10214, "loss": 0.88347, "time": 2.48217}
{"mode": "train", "epoch": 1, "iter": 90, "lr": 0.005, "memory": 5690, "data_time": 0.10196, "loss": 0.86761, "time": 2.48248}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.005, "memory": 5690, "data_time": 0.10183, "loss": 0.81434, "time": 2.48401}
{"mode": "val", "epoch": 1, "iter": 12, "lr": 0.005, "accuracy_top-1": 91.48352}
{"mode": "train", "epoch": 2, "iter": 10, "lr": 0.005, "memory": 5690, "data_time": 0.24125, "loss": 0.73266, "time": 2.61634}
{"mode": "train", "epoch": 2, "iter": 20, "lr": 0.005, "memory": 5690, "data_time": 0.10204, "loss": 0.68734, "time": 2.47785}
{"mode": "train", "epoch": 2, "iter": 30, "lr": 0.005, "memory": 5690, "data_time": 0.10218, "loss": 0.66333, "time": 2.47928}
{"mode": "train", "epoch": 2, "iter": 40, "lr": 0.005, "memory": 5690, "data_time": 0.10209, "loss": 0.63605, "time": 2.48068}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.005, "memory": 5690, "data_time": 0.10187, "loss": 0.61374, "time": 2.48336}
{"mode": "train", "epoch": 2, "iter": 60, "lr": 0.005, "memory": 5690, "data_time": 0.10196, "loss": 0.62294, "time": 2.48246}
{"mode": "train", "epoch": 2, "iter": 70, "lr": 0.005, "memory": 5690, "data_time": 0.10216, "loss": 0.70048, "time": 2.48353}
{"mode": "train", "epoch": 2, "iter": 80, "lr": 0.005, "memory": 5690, "data_time": 0.10197, "loss": 0.68003, "time": 2.48261}
{"mode": "train", "epoch": 2, "iter": 90, "lr": 0.005, "memory": 5690, "data_time": 0.10198, "loss": 0.60325, "time": 2.48113}
{"mode": "train", "epoch": 2, "iter": 100, "lr": 0.005, "memory": 5690, "data_time": 0.10235, "loss": 0.58657, "time": 2.48155}
{"mode": "val", "epoch": 2, "iter": 12, "lr": 0.005, "accuracy_top-1": 94.23077}
{"mode": "train", "epoch": 3, "iter": 10, "lr": 0.005, "memory": 5690, "data_time": 0.24903, "loss": 0.57761, "time": 2.62985}
{"mode": "train", "epoch": 3, "iter": 20, "lr": 0.005, "memory": 5690, "data_time": 0.10196, "loss": 0.54505, "time": 2.48204}
{"mode": "train", "epoch": 3, "iter": 30, "lr": 0.005, "memory": 5690, "data_time": 0.10202, "loss": 0.57645, "time": 2.48309}
{"mode": "train", "epoch": 3, "iter": 40, "lr": 0.005, "memory": 5690, "data_time": 0.10223, "loss": 0.5955, "time": 2.48105}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.005, "memory": 5690, "data_time": 0.10173, "loss": 0.55829, "time": 2.47869}
{"mode": "train", "epoch": 3, "iter": 60, "lr": 0.005, "memory": 5690, "data_time": 0.10222, "loss": 0.59138, "time": 2.48132}
{"mode": "train", "epoch": 3, "iter": 70, "lr": 0.005, "memory": 5690, "data_time": 0.10214, "loss": 0.60353, "time": 2.48227}
{"mode": "train", "epoch": 3, "iter": 80, "lr": 0.005, "memory": 5690, "data_time": 0.10197, "loss": 0.5929, "time": 2.48155}
{"mode": "train", "epoch": 3, "iter": 90, "lr": 0.005, "memory": 5690, "data_time": 0.10207, "loss": 0.61069, "time": 2.48084}
{"mode": "train", "epoch": 3, "iter": 100, "lr": 0.005, "memory": 5690, "data_time": 0.10215, "loss": 0.51595, "time": 2.47815}
{"mode": "val", "epoch": 3, "iter": 12, "lr": 0.005, "accuracy_top-1": 96.42857}
{"mode": "train", "epoch": 4, "iter": 10, "lr": 0.0005, "memory": 5690, "data_time": 0.25935, "loss": 0.5114, "time": 2.63389}
{"mode": "train", "epoch": 4, "iter": 20, "lr": 0.0005, "memory": 5690, "data_time": 0.10207, "loss": 0.53025, "time": 2.47899}
{"mode": "train", "epoch": 4, "iter": 30, "lr": 0.0005, "memory": 5690, "data_time": 0.1019, "loss": 0.55343, "time": 2.48043}
{"mode": "train", "epoch": 4, "iter": 40, "lr": 0.0005, "memory": 5690, "data_time": 0.10228, "loss": 0.49428, "time": 2.48188}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 0.0005, "memory": 5690, "data_time": 0.10203, "loss": 0.51734, "time": 2.48162}
{"mode": "train", "epoch": 4, "iter": 60, "lr": 0.0005, "memory": 5690, "data_time": 0.10234, "loss": 0.49785, "time": 2.48123}
{"mode": "train", "epoch": 4, "iter": 70, "lr": 0.0005, "memory": 5690, "data_time": 0.10224, "loss": 0.51597, "time": 2.47958}
{"mode": "train", "epoch": 4, "iter": 80, "lr": 0.0005, "memory": 5690, "data_time": 0.10196, "loss": 0.472, "time": 2.47954}
{"mode": "train", "epoch": 4, "iter": 90, "lr": 0.0005, "memory": 5690, "data_time": 0.10204, "loss": 0.49606, "time": 2.48082}
{"mode": "train", "epoch": 4, "iter": 100, "lr": 0.0005, "memory": 5690, "data_time": 0.10183, "loss": 0.50767, "time": 2.48109}
{"mode": "val", "epoch": 4, "iter": 12, "lr": 0.0005, "accuracy_top-1": 97.52748}
{"mode": "train", "epoch": 5, "iter": 10, "lr": 0.0005, "memory": 5690, "data_time": 0.24925, "loss": 0.50133, "time": 2.62859}
{"mode": "train", "epoch": 5, "iter": 20, "lr": 0.0005, "memory": 5690, "data_time": 0.10212, "loss": 0.46317, "time": 2.48171}
{"mode": "train", "epoch": 5, "iter": 30, "lr": 0.0005, "memory": 5690, "data_time": 0.10213, "loss": 0.49641, "time": 2.48114}
{"mode": "train", "epoch": 5, "iter": 40, "lr": 0.0005, "memory": 5690, "data_time": 0.10201, "loss": 0.47807, "time": 2.48067}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 0.0005, "memory": 5690, "data_time": 0.1024, "loss": 0.47769, "time": 2.47974}
{"mode": "train", "epoch": 5, "iter": 60, "lr": 0.0005, "memory": 5690, "data_time": 0.10216, "loss": 0.47967, "time": 2.48107}
{"mode": "train", "epoch": 5, "iter": 70, "lr": 0.0005, "memory": 5690, "data_time": 0.10221, "loss": 0.50098, "time": 2.48168}
{"mode": "train", "epoch": 5, "iter": 80, "lr": 0.0005, "memory": 5690, "data_time": 0.10223, "loss": 0.44706, "time": 2.48116}
{"mode": "train", "epoch": 5, "iter": 90, "lr": 0.0005, "memory": 5690, "data_time": 0.10208, "loss": 0.43992, "time": 2.48001}
{"mode": "train", "epoch": 5, "iter": 100, "lr": 0.0005, "memory": 5690, "data_time": 0.10215, "loss": 0.45769, "time": 2.4786}
{"mode": "val", "epoch": 5, "iter": 12, "lr": 0.0005, "accuracy_top-1": 97.52748}
